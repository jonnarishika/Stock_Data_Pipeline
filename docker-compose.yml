version: "3.8"

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5


  spark:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: spark
    depends_on:
      - kafka
    ports:
      - "4040:4040"
      - "8888:8888"

    volumes:
      - ./streaming:/home/jovyan/streaming
      - ./output:/home/jovyan/output

    command: ["sleep", "infinity"]

  postgres:
    image: postgres:15
    container_name: warehouse_postgres
    restart: always
    environment:
      POSTGRES_USER: stock_user
      POSTGRES_PASSWORD: stock_pass
      POSTGRES_DB: stock_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
  spark_loader:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: spark_loader
    depends_on:
      - spark
      - postgres
    volumes:
      - ./streaming:/home/jovyan/streaming
      - ./output:/home/jovyan/output
    command: >
      spark-submit
      --packages org.postgresql:postgresql:42.7.3
      /home/jovyan/streaming/spark_to_postgres.py

      
volumes:
  postgres_data:


